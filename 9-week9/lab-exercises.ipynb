{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Implement the Logistic Function\n",
    "\n",
    "In the following, implement the logistic function for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x, y, and format string must not be None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m alphas \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m5\u001b[39m]  \u001b[38;5;66;03m# Different values of alpha to shift the curve\u001b[39;00m\n\u001b[1;32m     13\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m---> 14\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogistic_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSimple logistic function\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/matplotlib/pyplot.py:3794\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3786\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   3787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\n\u001b[1;32m   3788\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3793\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[0;32m-> 3794\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3795\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3796\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3797\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3798\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3799\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3800\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/matplotlib/axes/_axes.py:1779\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1776\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1777\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1778\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1779\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1781\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/matplotlib/axes/_base.py:296\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, axes, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    295\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 296\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/matplotlib/axes/_base.py:447\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;66;03m# Don't allow any None value; these would be up-converted to one\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# element array of None which causes problems downstream.\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m tup):\n\u001b[0;32m--> 447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx, y, and format string must not be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    449\u001b[0m kw \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prop_name, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinestyle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmarker\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    451\u001b[0m                           (linestyle, marker, color)):\n",
      "\u001b[0;31mValueError\u001b[0m: x, y, and format string must not be None"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+AAAAH/CAYAAADXOLcaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAh80lEQVR4nO3df2zV9b348VcLttXMVrxcyo9bx9Vd5zYVHEhXHTHedDaZYZc/btaLCxCi87pxjdrsTvAHnXOj3E0NyRVHZO665MYLG5neZZB6Xa9k2bU3ZPxINBcwjjGIWQvcXVqGG5X28/1jWfftKMgp9AXI45GcP/r2/T7nfcybhief86OsKIoiAAAAgFFVfrY3AAAAABcCAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAlKDvCf/OQnMWfOnJg8eXKUlZXFSy+99J5rNm3aFB//+MejsrIyPvShD8Xzzz8/gq0CAADA+avkAD9y5EhMmzYtVq1adUrzf/GLX8Ttt98et956a2zfvj3uv//+uOuuu+Lll18uebMAAABwvioriqIY8eKysnjxxRdj7ty5J5zz4IMPxoYNG+KNN94YHPu7v/u7OHToULS3t4/0oQEAAOC8Mna0H6CzszMaGxuHjDU1NcX9999/wjVHjx6No0ePDv48MDAQv/71r+PP/uzPoqysbLS2CgAAABERURRFHD58OCZPnhzl5Wfm49NGPcC7urqitrZ2yFhtbW309vbGb3/727j44ouPW9PW1haPPfbYaG8NAAAATmrfvn3xF3/xF2fkvkY9wEdi6dKl0dLSMvhzT09PXHHFFbFv376orq4+izsDAADgQtDb2xt1dXVx6aWXnrH7HPUAnzhxYnR3dw8Z6+7ujurq6mGvfkdEVFZWRmVl5XHj1dXVAhwAAIA0Z/Jt0KP+PeANDQ3R0dExZOyVV16JhoaG0X5oAAAAOGeUHOC/+c1vYvv27bF9+/aI+P3XjG3fvj327t0bEb9/+fiCBQsG599zzz2xe/fu+PKXvxw7d+6MZ555Jr73ve/FAw88cGaeAQAAAJwHSg7wn/3sZ3HDDTfEDTfcEBERLS0tccMNN8SyZcsiIuJXv/rVYIxHRPzlX/5lbNiwIV555ZWYNm1aPPnkk/Htb387mpqaztBTAAAAgHPfaX0PeJbe3t6oqamJnp4e7wEHAABg1I1Gh476e8ABAAAAAQ4AAAApBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQIIRBfiqVati6tSpUVVVFfX19bF58+aTzl+5cmV8+MMfjosvvjjq6urigQceiN/97ncj2jAAAACcj0oO8HXr1kVLS0u0trbG1q1bY9q0adHU1BT79+8fdv4LL7wQS5YsidbW1tixY0c899xzsW7dunjooYdOe/MAAABwvig5wJ966qn4/Oc/H4sWLYqPfvSjsXr16rjkkkviO9/5zrDzX3vttbj55pvjjjvuiKlTp8Ztt90W8+bNe8+r5gAAAPB+UlKA9/X1xZYtW6KxsfGPd1BeHo2NjdHZ2Tnsmptuuim2bNkyGNy7d++OjRs3xqc//enT2DYAAACcX8aWMvngwYPR398ftbW1Q8Zra2tj586dw66544474uDBg/HJT34yiqKIY8eOxT333HPSl6AfPXo0jh49Ovhzb29vKdsEAACAc86ofwr6pk2bYvny5fHMM8/E1q1b4wc/+EFs2LAhHn/88ROuaWtri5qamsFbXV3daG8TAAAARlVZURTFqU7u6+uLSy65JNavXx9z584dHF+4cGEcOnQo/v3f//24NbNnz45PfOIT8c1vfnNw7F//9V/j7rvvjt/85jdRXn78vwEMdwW8rq4uenp6orq6+lS3CwAAACPS29sbNTU1Z7RDS7oCXlFRETNmzIiOjo7BsYGBgejo6IiGhoZh17zzzjvHRfaYMWMiIuJE7V9ZWRnV1dVDbgAAAHA+K+k94BERLS0tsXDhwpg5c2bMmjUrVq5cGUeOHIlFixZFRMSCBQtiypQp0dbWFhERc+bMiaeeeipuuOGGqK+vj7feeiseffTRmDNnzmCIAwAAwPtdyQHe3NwcBw4ciGXLlkVXV1dMnz492tvbBz+Ybe/evUOueD/yyCNRVlYWjzzySLz99tvx53/+5zFnzpz4+te/fuaeBQAAAJzjSnoP+NkyGq+9BwAAgBM56+8BBwAAAEZGgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQIIRBfiqVati6tSpUVVVFfX19bF58+aTzj906FAsXrw4Jk2aFJWVlXH11VfHxo0bR7RhAAAAOB+NLXXBunXroqWlJVavXh319fWxcuXKaGpqil27dsWECROOm9/X1xef+tSnYsKECbF+/fqYMmVK/PKXv4zLLrvsTOwfAAAAzgtlRVEUpSyor6+PG2+8MZ5++umIiBgYGIi6urq49957Y8mSJcfNX716dXzzm9+MnTt3xkUXXTSiTfb29kZNTU309PREdXX1iO4DAAAATtVodGhJL0Hv6+uLLVu2RGNj4x/voLw8Ghsbo7Ozc9g1P/zhD6OhoSEWL14ctbW1ce2118by5cujv7//hI9z9OjR6O3tHXIDAACA81lJAX7w4MHo7++P2traIeO1tbXR1dU17Jrdu3fH+vXro7+/PzZu3BiPPvpoPPnkk/G1r33thI/T1tYWNTU1g7e6urpStgkAAADnnFH/FPSBgYGYMGFCPPvsszFjxoxobm6Ohx9+OFavXn3CNUuXLo2enp7B2759+0Z7mwAAADCqSvoQtvHjx8eYMWOiu7t7yHh3d3dMnDhx2DWTJk2Kiy66KMaMGTM49pGPfCS6urqir68vKioqjltTWVkZlZWVpWwNAAAAzmklXQGvqKiIGTNmREdHx+DYwMBAdHR0RENDw7Brbr755njrrbdiYGBgcOzNN9+MSZMmDRvfAAAA8H5U8kvQW1paYs2aNfHd7343duzYEV/4whfiyJEjsWjRooiIWLBgQSxdunRw/he+8IX49a9/Hffdd1+8+eabsWHDhli+fHksXrz4zD0LAAAAOMeV/D3gzc3NceDAgVi2bFl0dXXF9OnTo729ffCD2fbu3Rvl5X/s+rq6unj55ZfjgQceiOuvvz6mTJkS9913Xzz44INn7lkAAADAOa7k7wE/G3wPOAAAAJnO+veAAwAAACMjwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASDCiAF+1alVMnTo1qqqqor6+PjZv3nxK69auXRtlZWUxd+7ckTwsAAAAnLdKDvB169ZFS0tLtLa2xtatW2PatGnR1NQU+/fvP+m6PXv2xJe+9KWYPXv2iDcLAAAA56uSA/ypp56Kz3/+87Fo0aL46Ec/GqtXr45LLrkkvvOd75xwTX9/f3zuc5+Lxx57LK688srT2jAAAACcj0oK8L6+vtiyZUs0Njb+8Q7Ky6OxsTE6OztPuO6rX/1qTJgwIe68885TepyjR49Gb2/vkBsAAACcz0oK8IMHD0Z/f3/U1tYOGa+trY2urq5h1/z0pz+N5557LtasWXPKj9PW1hY1NTWDt7q6ulK2CQAAAOecUf0U9MOHD8f8+fNjzZo1MX78+FNet3Tp0ujp6Rm87du3bxR3CQAAAKNvbCmTx48fH2PGjInu7u4h493d3TFx4sTj5v/85z+PPXv2xJw5cwbHBgYGfv/AY8fGrl274qqrrjpuXWVlZVRWVpayNQAAADinlXQFvKKiImbMmBEdHR2DYwMDA9HR0RENDQ3Hzb/mmmvi9ddfj+3btw/ePvOZz8Stt94a27dv99JyAAAALhglXQGPiGhpaYmFCxfGzJkzY9asWbFy5co4cuRILFq0KCIiFixYEFOmTIm2traoqqqKa6+9dsj6yy67LCLiuHEAAAB4Pys5wJubm+PAgQOxbNmy6OrqiunTp0d7e/vgB7Pt3bs3ystH9a3lAAAAcN4pK4qiONubeC+9vb1RU1MTPT09UV1dfba3AwAAwPvcaHSoS9UAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAECCEQX4qlWrYurUqVFVVRX19fWxefPmE85ds2ZNzJ49O8aNGxfjxo2LxsbGk84HAACA96OSA3zdunXR0tISra2tsXXr1pg2bVo0NTXF/v37h52/adOmmDdvXrz66qvR2dkZdXV1cdttt8Xbb7992psHAACA80VZURRFKQvq6+vjxhtvjKeffjoiIgYGBqKuri7uvffeWLJkyXuu7+/vj3HjxsXTTz8dCxYsOKXH7O3tjZqamujp6Ynq6upStgsAAAAlG40OLekKeF9fX2zZsiUaGxv/eAfl5dHY2BidnZ2ndB/vvPNOvPvuu3H55ZefcM7Ro0ejt7d3yA0AAADOZyUF+MGDB6O/vz9qa2uHjNfW1kZXV9cp3ceDDz4YkydPHhLxf6qtrS1qamoGb3V1daVsEwAAAM45qZ+CvmLFili7dm28+OKLUVVVdcJ5S5cujZ6ensHbvn37EncJAAAAZ97YUiaPHz8+xowZE93d3UPGu7u7Y+LEiSdd+8QTT8SKFSvixz/+cVx//fUnnVtZWRmVlZWlbA0AAADOaSVdAa+oqIgZM2ZER0fH4NjAwEB0dHREQ0PDCdd94xvfiMcffzza29tj5syZI98tAAAAnKdKugIeEdHS0hILFy6MmTNnxqxZs2LlypVx5MiRWLRoUURELFiwIKZMmRJtbW0REfFP//RPsWzZsnjhhRdi6tSpg+8V/8AHPhAf+MAHzuBTAQAAgHNXyQHe3NwcBw4ciGXLlkVXV1dMnz492tvbBz+Ybe/evVFe/scL69/61reir68v/vZv/3bI/bS2tsZXvvKV09s9AAAAnCdK/h7ws8H3gAMAAJDprH8POAAAADAyAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQjCvBVq1bF1KlTo6qqKurr62Pz5s0nnf/9738/rrnmmqiqqorrrrsuNm7cOKLNAgAAwPmq5ABft25dtLS0RGtra2zdujWmTZsWTU1NsX///mHnv/baazFv3ry48847Y9u2bTF37tyYO3duvPHGG6e9eQAAADhflBVFUZSyoL6+Pm688cZ4+umnIyJiYGAg6urq4t57740lS5YcN7+5uTmOHDkSP/rRjwbHPvGJT8T06dNj9erVp/SYvb29UVNTEz09PVFdXV3KdgEAAKBko9GhY0uZ3NfXF1u2bImlS5cOjpWXl0djY2N0dnYOu6azszNaWlqGjDU1NcVLL710wsc5evRoHD16dPDnnp6eiPj9/wAAAAAYbX/ozxKvWZ9USQF+8ODB6O/vj9ra2iHjtbW1sXPnzmHXdHV1DTu/q6vrhI/T1tYWjz322HHjdXV1pWwXAAAATsv//u//Rk1NzRm5r5ICPMvSpUuHXDU/dOhQfPCDH4y9e/eesScO55re3t6oq6uLffv2easF71vOORcC55wLgXPOhaCnpyeuuOKKuPzyy8/YfZYU4OPHj48xY8ZEd3f3kPHu7u6YOHHisGsmTpxY0vyIiMrKyqisrDxuvKamxh9w3veqq6udc973nHMuBM45FwLnnAtBefmZ+/buku6poqIiZsyYER0dHYNjAwMD0dHREQ0NDcOuaWhoGDI/IuKVV1454XwAAAB4Pyr5JegtLS2xcOHCmDlzZsyaNStWrlwZR44ciUWLFkVExIIFC2LKlCnR1tYWERH33Xdf3HLLLfHkk0/G7bffHmvXro2f/exn8eyzz57ZZwIAAADnsJIDvLm5OQ4cOBDLli2Lrq6umD59erS3tw9+0NrevXuHXKK/6aab4oUXXohHHnkkHnroofirv/qreOmll+Laa6895cesrKyM1tbWYV+WDu8XzjkXAuecC4FzzoXAOedCMBrnvOTvAQcAAABKd+beTQ4AAACckAAHAACABAIcAAAAEghwAAAASHDOBPiqVati6tSpUVVVFfX19bF58+aTzv/+978f11xzTVRVVcV1110XGzduTNopjFwp53zNmjUxe/bsGDduXIwbNy4aGxvf888FnAtK/X3+B2vXro2ysrKYO3fu6G4QzoBSz/mhQ4di8eLFMWnSpKisrIyrr77a310455V6zleuXBkf/vCH4+KLL466urp44IEH4ne/+13SbqE0P/nJT2LOnDkxefLkKCsri5deeuk912zatCk+/vGPR2VlZXzoQx+K559/vuTHPScCfN26ddHS0hKtra2xdevWmDZtWjQ1NcX+/fuHnf/aa6/FvHnz4s4774xt27bF3LlzY+7cufHGG28k7xxOXannfNOmTTFv3rx49dVXo7OzM+rq6uK2226Lt99+O3nncOpKPed/sGfPnvjSl74Us2fPTtopjFyp57yvry8+9alPxZ49e2L9+vWxa9euWLNmTUyZMiV553DqSj3nL7zwQixZsiRaW1tjx44d8dxzz8W6devioYceSt45nJojR47EtGnTYtWqVac0/xe/+EXcfvvtceutt8b27dvj/vvvj7vuuitefvnl0h64OAfMmjWrWLx48eDP/f39xeTJk4u2trZh53/2s58tbr/99iFj9fX1xd///d+P6j7hdJR6zv/UsWPHiksvvbT47ne/O1pbhNM2knN+7Nix4qabbiq+/e1vFwsXLiz+5m/+JmGnMHKlnvNvfetbxZVXXln09fVlbRFOW6nnfPHixcVf//VfDxlraWkpbr755lHdJ5wJEVG8+OKLJ53z5S9/ufjYxz42ZKy5ubloamoq6bHO+hXwvr6+2LJlSzQ2Ng6OlZeXR2NjY3R2dg67prOzc8j8iIimpqYTzoezbSTn/E+988478e6778bll18+WtuE0zLSc/7Vr341JkyYEHfeeWfGNuG0jOSc//CHP4yGhoZYvHhx1NbWxrXXXhvLly+P/v7+rG1DSUZyzm+66abYsmXL4MvUd+/eHRs3boxPf/rTKXuG0XamGnTsmdzUSBw8eDD6+/ujtrZ2yHhtbW3s3Llz2DVdXV3Dzu/q6hq1fcLpGMk5/1MPPvhgTJ48+bg/+HCuGMk5/+lPfxrPPfdcbN++PWGHcPpGcs53794d//mf/xmf+9znYuPGjfHWW2/FF7/4xXj33XejtbU1Y9tQkpGc8zvuuCMOHjwYn/zkJ6Moijh27Fjcc889XoLO+8aJGrS3tzd++9vfxsUXX3xK93PWr4AD723FihWxdu3aePHFF6OqqupsbwfOiMOHD8f8+fNjzZo1MX78+LO9HRg1AwMDMWHChHj22WdjxowZ0dzcHA8//HCsXr36bG8NzphNmzbF8uXL45lnnomtW7fGD37wg9iwYUM8/vjjZ3trcE4561fAx48fH2PGjInu7u4h493d3TFx4sRh10ycOLGk+XC2jeSc/8ETTzwRK1asiB//+Mdx/fXXj+Y24bSUes5//vOfx549e2LOnDmDYwMDAxERMXbs2Ni1a1dcddVVo7tpKNFIfp9PmjQpLrroohgzZszg2Ec+8pHo6uqKvr6+qKioGNU9Q6lGcs4fffTRmD9/ftx1110REXHdddfFkSNH4u67746HH344ystd9+P8dqIGra6uPuWr3xHnwBXwioqKmDFjRnR0dAyODQwMREdHRzQ0NAy7pqGhYcj8iIhXXnnlhPPhbBvJOY+I+MY3vhGPP/54tLe3x8yZMzO2CiNW6jm/5ppr4vXXX4/t27cP3j7zmc8MfrpoXV1d5vbhlIzk9/nNN98cb7311uA/MEVEvPnmmzFp0iTxzTlpJOf8nXfeOS6y//CPTr//jCs4v52xBi3t8+FGx9q1a4vKysri+eefL/7nf/6nuPvuu4vLLrus6OrqKoqiKObPn18sWbJkcP5//dd/FWPHji2eeOKJYseOHUVra2tx0UUXFa+//vrZegrwnko95ytWrCgqKiqK9evXF7/61a8Gb4cPHz5bTwHeU6nn/E/5FHTOB6We87179xaXXnpp8Q//8A/Frl27ih/96EfFhAkTiq997Wtn6ynAeyr1nLe2thaXXnpp8W//9m/F7t27i//4j/8orrrqquKzn/3s2XoKcFKHDx8utm3bVmzbtq2IiOKpp54qtm3bVvzyl78siqIolixZUsyfP39w/u7du4tLLrmk+Md//Mdix44dxapVq4oxY8YU7e3tJT3uORHgRVEU//zP/1xcccUVRUVFRTFr1qziv//7vwf/2y233FIsXLhwyPzvfe97xdVXX11UVFQUH/vYx4oNGzYk7xhKV8o5/+AHP1hExHG31tbW/I1DCUr9ff7/E+CcL0o956+99lpRX19fVFZWFldeeWXx9a9/vTh27FjyrqE0pZzzd999t/jKV75SXHXVVUVVVVVRV1dXfPGLXyz+7//+L3/jcApeffXVYf+u/YdzvXDhwuKWW245bs306dOLioqK4sorryz+5V/+peTHLSsKrwkBAACA0XbW3wMOAAAAFwIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkOD/Ac7nRNdHzOW8AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def logistic_function(X):\n",
    "    #YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "\n",
    "# Graph 1: Modifying alpha (intercept term)\n",
    "x = np.linspace(-10, 10, 200)  # Generate 200 points between -10 and 10\n",
    "alphas = [-5, 0, 5]  # Different values of alpha to shift the curve\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(x, logistic_function(x))\n",
    "plt.title('Simple logistic function')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Probability')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Create a Logistic Regression class\n",
    "\n",
    "Use the logistic function above to derive the probabilities inside the `fit` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.utils.validation import check_X_y, check_array\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "class LogisticRegression(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000, tolerance=1e-6):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.tolerance = tolerance\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        self.classes_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X, y = check_X_y(X, y, ensure_2d=True)\n",
    "        n_samples, n_features = X.shape\n",
    "        self.classes = unique_labels(y)\n",
    "        # Initialize parameters\n",
    "        self.coef_ = np.zeros(n_features)\n",
    "        self.intercept_ = 0\n",
    "\n",
    "        for _ in range(self.n_iterations):\n",
    "            # Make predictions\n",
    "            y_pred = self._predict_proba(X)\n",
    "\n",
    "            # Calculate gradients\n",
    "            dw = (1 / n_samples) * np.dot(X.T, (y_pred - y))\n",
    "            db = (1 / n_samples) * np.sum(y_pred - y)\n",
    "\n",
    "            # Update parameters\n",
    "            self.coef_ -= self.learning_rate * dw\n",
    "            self.intercept_ -= self.learning_rate * db\n",
    "\n",
    "            # Check for convergence\n",
    "            if np.all(np.abs(self.learning_rate * dw) < self.tolerance):\n",
    "                break\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _predict_proba(self, X):\n",
    "        linear_pred = np.dot(X, self.coef_) + self.intercept_\n",
    "        return sigmoid(linear_pred)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X = check_array(X, ensure_2d=True)\n",
    "        return self._predict_proba(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = check_array(X, ensure_2d=True)\n",
    "        probs = self._predict_proba(X)\n",
    "        return np.where(probs>=0.5, self.classes_[1], self.classes_[0])\n",
    "\n",
    "    def _compute_loss(self, y_true, y_pred):\n",
    "        return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Evaluating a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5255/2801119109.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Sex'] = X['Sex'].map({'male': 0, 'female': 1})\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m pipeline\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/pipeline.py:601\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[0;34m(self, X, **params)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    600\u001b[0m         Xt \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mtransform(Xt)\n\u001b[0;32m--> 601\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n\u001b[1;32m    604\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m process_routing(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "Cell \u001b[0;32mIn[27], line 55\u001b[0m, in \u001b[0;36mLogisticRegression.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     53\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(X, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     54\u001b[0m probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_proba(X)\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mwhere(probs\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, f1_score\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv\"\n",
    "titanic = pd.read_csv(url)\n",
    "\n",
    "# Preprocessing\n",
    "X = titanic[['Pclass', 'Sex', 'Age', 'Fare']]\n",
    "y = titanic['Survived']\n",
    "\n",
    "# Encode 'Sex' column\n",
    "X['Sex'] = X['Sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "\n",
    "# Create preprocessing pipeline\n",
    "numeric_features = ['Age', 'Fare']\n",
    "numeric_transformer = make_pipeline(SimpleImputer(strategy='median'), StandardScaler())\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features)\n",
    "    ])\n",
    "\n",
    "# Create the full pipeline\n",
    "pipeline = make_pipeline(preprocessor, LogisticRegression())\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1\n",
    "\n",
    "Use the scikit-learn metrics library to manually calculate precision, recall, confusion matrix, and F1 score for our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Your code here\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m precision_score, recall_score, confusion_matrix, f1_score\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecision\u001b[39m\u001b[38;5;124m\"\u001b[39m, precision_score(y_test, \u001b[43my_pred\u001b[49m))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecall\u001b[39m\u001b[38;5;124m\"\u001b[39m, recall_score(y_test, y_pred))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, f1_score\n",
    "\n",
    "print(\"Precision\", precision_score(y_test, y_pred))\n",
    "print(\"Recall\", recall_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "\n",
    "Use cross_val_score to compute the F1 score using 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 371, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 89, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 200, in _get_response_values\n",
      "    target_type = type_of_target(classes)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/multiclass.py\", line 306, in type_of_target\n",
      "    raise ValueError(\n",
      "ValueError: Expected array-like (array or non-string sequence), got None\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 371, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 89, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 200, in _get_response_values\n",
      "    target_type = type_of_target(classes)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/multiclass.py\", line 306, in type_of_target\n",
      "    raise ValueError(\n",
      "ValueError: Expected array-like (array or non-string sequence), got None\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 371, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 89, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 200, in _get_response_values\n",
      "    target_type = type_of_target(classes)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/multiclass.py\", line 306, in type_of_target\n",
      "    raise ValueError(\n",
      "ValueError: Expected array-like (array or non-string sequence), got None\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 371, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 89, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 200, in _get_response_values\n",
      "    target_type = type_of_target(classes)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/multiclass.py\", line 306, in type_of_target\n",
      "    raise ValueError(\n",
      "ValueError: Expected array-like (array or non-string sequence), got None\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 371, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 89, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 200, in _get_response_values\n",
      "    target_type = type_of_target(classes)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/multiclass.py\", line 306, in type_of_target\n",
      "    raise ValueError(\n",
      "ValueError: Expected array-like (array or non-string sequence), got None\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "# Hint: Use cross_val_score with cv=5 and scoring='f1'\n",
    "cv_scores = cross_val_score(pipeline, X, y, cv=5, scoring = \"f1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "\n",
    "Use cross_validate with a StratifiedKFold sampler to compute multiple metrics (accuracy, precision, recall, and F1 score) using 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Hint: \n",
    "# 1. Create a StratifiedKFold object\n",
    "# 2. Define a dictionary of scoring metrics\n",
    "# 3. Use cross_validate with the StratifiedKFold object and the scoring dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS\n",
    "\n",
    "If you finish early, try creating learning curves to visualize how the model's performance changes with increasing amounts of training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Your code here\n",
    "# Hint:\n",
    "# 1. Use learning_curve function\n",
    "# 2. Plot the results using matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Implement Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def softmax(z):\n",
    "    # Your code here\n",
    "   \n",
    "\n",
    "# Example of how softmax works\n",
    "example_z = np.array([[1.0, 2.0, 0.5], [-1.0, 0.0, 3.0]])\n",
    "example_softmax = softmax(example_z)\n",
    "print(\"\\nSoftmax example:\")\n",
    "print(\"Input:\")\n",
    "print(example_z)\n",
    "print(\"Softmax output:\")\n",
    "print(example_softmax)\n",
    "print(\"Sum of probabilities for each row:\")\n",
    "print(np.sum(example_softmax, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Implement Multiple Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class LogisticRegression(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000, tolerance=1e-6):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.tolerance = tolerance\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        self.classes_ = None\n",
    "        self.n_classes_ = None\n",
    "        self.label_encoder = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X, y = check_X_y(X, y, ensure_2d=True)\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        y_encoded = self.label_encoder.fit_transform(y)\n",
    "        self.classes_ = self.label_encoder.classes_\n",
    "        self.n_classes_ = len(self.classes_)\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # Initialize parameters\n",
    "        self.coef_ = np.zeros((self.n_classes_, n_features))\n",
    "        self.intercept_ = np.zeros(self.n_classes_)\n",
    "\n",
    "        # Convert y to one-hot encoding\n",
    "        y_onehot = np.eye(self.n_classes_)[y_encoded]\n",
    "\n",
    "\n",
    "        # What goes here?\n",
    "        for _ in range(self.n_iterations):\n",
    "            # Make predictions\n",
    "            y_pred = self._predict_proba(X)\n",
    "\n",
    "            # Calculate gradients\n",
    "\n",
    "            # Update parameters\n",
    "\n",
    "            # Check for convergence\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _predict_proba(self, X):\n",
    "        # What goes here?\n",
    "        pass\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X = check_array(X, ensure_2d=True)\n",
    "        return self._predict_proba(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = check_array(X, ensure_2d=True)\n",
    "        y_pred = np.argmax(self._predict_proba(X), axis=1)\n",
    "        return self.label_encoder.inverse_transform(y_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
